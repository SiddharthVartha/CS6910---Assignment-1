{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "_oG4bR3ld4vd",
        "outputId": "950a0e0e-fe9b-429f-e2bb-1e0bedd7ff66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.41.0-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.41.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "26086e13a33f4883bf6f1c6e9b64701a",
            "e6a3c6f603cd4af4b8fb629d6527325a",
            "a8515cffb7324589a8ad049827f4fccc",
            "f2a3ce8eed504589b7cb064dc3f9e360",
            "d12c315ce7434ff8a456f2adbb789a47",
            "986da0d7a35f4a66bd3dd44e4adaacbe",
            "21233b0c5fa04e0d83e63d0b69b6d9fc",
            "2b7191559d3e4ba5a40a542c4115fb9f",
            "a6197395d2f849f2b851536402482a93",
            "c7d2e6a5140f42bc8f8d37832a8cae73",
            "6106fe2e5cb54358a7cb4ac0682d7cf8",
            "b99aebdc96ba44ff9d973fcb909834be",
            "79c76a5289f5480b88dbe06cb7dfc8f0",
            "ba74faef64f64b8d8a0e7beadae99586",
            "d21e3f7e538b43448f8fa3ade1b61a32",
            "e02a0968f79f4ed2a1b2bcaee2088be3"
          ]
        },
        "id": "5rM7z30DGsVH",
        "outputId": "a868f599-3a39-42f5-8036-ee947f355038"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Create sweep with ID: g44d3cz0\n",
            "Sweep URL: https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 84gh8f5n with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teach_layer_neuron: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teps: 1e-10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization_func: Xavier\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_type: cross_entropy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_hidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nestrov\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m063\u001b[0m (\u001b[33mdeep_learn_assignment_1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240310_230443-84gh8f5n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/84gh8f5n' target=\"_blank\">northern-sweep-1</a></strong> to <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/84gh8f5n' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/84gh8f5n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54000/54000 [07:15<00:00, 123.99it/s]\n",
            "100%|██████████| 54000/54000 [07:11<00:00, 125.14it/s]\n",
            "100%|██████████| 54000/54000 [07:14<00:00, 124.42it/s]\n",
            "100%|██████████| 54000/54000 [07:10<00:00, 125.52it/s]\n",
            "100%|██████████| 54000/54000 [07:11<00:00, 125.10it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26086e13a33f4883bf6f1c6e9b64701a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▁▆▇█</td></tr><tr><td>Loss</td><td>██▃▁▁</td></tr><tr><td>Validation_Accuracy</td><td>▁▃▇██</td></tr><tr><td>Validation_Loss</td><td>█▅▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.76722</td></tr><tr><td>Loss</td><td>0.63838</td></tr><tr><td>Validation_Accuracy</td><td>0.78417</td></tr><tr><td>Validation_Loss</td><td>0.6069</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">northern-sweep-1</strong> at: <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/84gh8f5n' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/84gh8f5n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240310_230443-84gh8f5n/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vc74vzlt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teach_layer_neuron: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teps: 1e-10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teta: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization_func: Xavier\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_type: cross_entropy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_hidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240310_234157-vc74vzlt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/vc74vzlt' target=\"_blank\">happy-sweep-2</a></strong> to <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/sweeps/g44d3cz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/vc74vzlt' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/vc74vzlt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54000/54000 [02:05<00:00, 431.69it/s]\n",
            "100%|██████████| 54000/54000 [02:05<00:00, 431.19it/s]\n",
            "100%|██████████| 54000/54000 [02:04<00:00, 432.77it/s]\n",
            "100%|██████████| 54000/54000 [02:03<00:00, 436.78it/s]\n",
            "100%|██████████| 54000/54000 [02:03<00:00, 437.19it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.002 MB uploaded\\r'), FloatProgress(value=0.4539219888555508, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6197395d2f849f2b851536402482a93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▄▇██</td></tr><tr><td>Loss</td><td>█▄▂▁▁</td></tr><tr><td>Validation_Accuracy</td><td>▁▇███</td></tr><tr><td>Validation_Loss</td><td>█▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.73452</td></tr><tr><td>Loss</td><td>0.69915</td></tr><tr><td>Validation_Accuracy</td><td>0.75583</td></tr><tr><td>Validation_Loss</td><td>0.656</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">happy-sweep-2</strong> at: <a href='https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/vc74vzlt' target=\"_blank\">https://wandb.ai/deep_learn_assignment_1/deep_learn_assignment_1/runs/vc74vzlt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240310_234157-vc74vzlt/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "# Load Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "# Display sample images\n",
        "def display_sample_images():\n",
        "    label = {0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}\n",
        "    print_Once = [1] * 10\n",
        "    count = 10\n",
        "    for i in range(60000):\n",
        "        if count == 0:\n",
        "            break\n",
        "        if print_Once[y_train[i]]:\n",
        "            print_Once[y_train[i]] -= 1\n",
        "            count -= 1\n",
        "            plt.figure(figsize=(1, 1))\n",
        "            plt.imshow(x_train[i], cmap=\"Greys\")\n",
        "            plt.title(\"{}\".format(label[y_train[i]]))\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.show()\n",
        "\n",
        "# Initialize weights and biases\n",
        "def initialize_weights(initialization_func, prev_layer_neurons, no_of_hidden_layers, classes,each_layer_neuron):\n",
        "    theta = []\n",
        "    for i in range(2 * (no_of_hidden_layers + 1)):\n",
        "        theta.append([])\n",
        "    for i in range(no_of_hidden_layers):\n",
        "        neurons_in_layer = each_layer_neuron\n",
        "        make_weights(theta, neurons_in_layer, prev_layer_neurons, i, initialization_func)\n",
        "        make_biases(theta, neurons_in_layer, no_of_hidden_layers + 1 + i, initialization_func)\n",
        "        prev_layer_neurons = neurons_in_layer\n",
        "    make_weights(theta, classes, prev_layer_neurons, no_of_hidden_layers, initialization_func)\n",
        "    make_biases(theta, classes, 2 * (no_of_hidden_layers + 1) - 1, initialization_func)\n",
        "    return theta\n",
        "\n",
        "# Make weights\n",
        "def make_weights(theta, curr_layer_neurons, prev_layer_neurons, layer_no, initialization_func):\n",
        "    if initialization_func == \"random\":\n",
        "        theta[layer_no] = np.float128(np.random.randn(curr_layer_neurons, prev_layer_neurons))\n",
        "    elif initialization_func == \"Xavier\":\n",
        "        factor = np.sqrt(6.0 / (curr_layer_neurons + prev_layer_neurons))\n",
        "        theta[layer_no] = np.float128(np.random.uniform(low=-factor, high=factor, size=(curr_layer_neurons, prev_layer_neurons)))\n",
        "\n",
        "# Make biases\n",
        "def make_biases(theta, curr_layer_neurons, layer_no, initialization_func):\n",
        "    if initialization_func == \"random\":\n",
        "        theta[layer_no] = np.float128(np.random.randn(curr_layer_neurons, 1))\n",
        "    elif initialization_func == \"Xavier\":\n",
        "        theta[layer_no] = np.float128(np.zeros((curr_layer_neurons, 1)))\n",
        "\n",
        "# Calculate activation function\n",
        "def calc_activation(a, activation_func):\n",
        "    h = []\n",
        "    a=np.round(a,6)\n",
        "    for i in range(len(a)):\n",
        "        if activation_func == \"sigmoid\":\n",
        "          if(a[i][0]<-30):\n",
        "            h.append(0.0)\n",
        "          else:\n",
        "            h.append(1/(1+np.exp(-a[i][0])))\n",
        "\n",
        "        elif activation_func == \"ReLU\":\n",
        "            h.append(max(0, a[i][0]))\n",
        "\n",
        "        elif activation_func == \"tanh\":\n",
        "           if(a[i][0]<-30):\n",
        "              h.append(-1.0)\n",
        "           else:\n",
        "              h.append(2 * (1 / (1 + np.exp(-2 * a[i][0]))) - 1)\n",
        "    h = np.array(h)\n",
        "    h_new = h.reshape((len(h), 1))\n",
        "    return h_new\n",
        "\n",
        "# Calculate activation derivative\n",
        "def calc_activation_derivative(a, activation_func):\n",
        "    if activation_func == \"sigmoid\":\n",
        "        a=0.0 if(a<-30) else 1/(1+np.exp(a))\n",
        "        return a * (1 - (a))\n",
        "    elif activation_func == \"ReLU\":\n",
        "        return np.where(a > 0, 1, 0)\n",
        "    elif activation_func == \"tanh\":\n",
        "        return 1-(np.tanh(a)**2)\n",
        "\n",
        "def calc_gdash(ak,activationFunc):\n",
        "  gdsh=[]\n",
        "  for i in ak:\n",
        "      gdsh.append(calc_activation_derivative(i[0],activationFunc))\n",
        "  gdsh=np.array(gdsh)\n",
        "  gdshNew=gdsh.reshape((len(gdsh),1))\n",
        "  return gdshNew\n",
        "\n",
        "def calc_aL(aL,y):\n",
        "  aL[y][0]=-(1-aL[y][0])\n",
        "  return aL\n",
        "\n",
        "# Calculate softmax\n",
        "def calc_softmax(a):\n",
        "    #return np.exp(a) / np.sum(np.exp(a), axis=0)\n",
        "    exp_a = np.exp(a - np.max(a, axis=0))\n",
        "    return exp_a / np.sum(exp_a, axis=0)\n",
        "\n",
        "# Forward propagation\n",
        "def forward_propagation(theta, inp_list, activation_func,no_of_hidden_layers):\n",
        "    a_h_list = []\n",
        "    h = inp_list\n",
        "    for i in range(no_of_hidden_layers):\n",
        "        a = np.dot(theta[i], h) + theta[no_of_hidden_layers + 1 + i]\n",
        "        a_h_list.append(a)\n",
        "        h = calc_activation(a, activation_func)\n",
        "        a_h_list.append(h)\n",
        "    a = np.dot(theta[no_of_hidden_layers], h) + theta[-1]\n",
        "    a_h_list.append(a)\n",
        "    y_hat = calc_softmax(a)\n",
        "    a_h_list.append(y_hat)\n",
        "    return a_h_list\n",
        "\n",
        "# Calculate loss\n",
        "def calc_loss(yhat, actual, loss_type):\n",
        "\n",
        "    if loss_type == \"mse\":\n",
        "        sum=0\n",
        "        for i in range(10):\n",
        "          if(i==actual):\n",
        "            sum+=(1-yhat[i][0])**2\n",
        "          else:\n",
        "            sum+=yhat[i][0]**2\n",
        "        return  sum/10\n",
        "    elif loss_type == \"cross_entropy\":\n",
        "        prediction=yhat[actual][0]\n",
        "        if(not prediction):\n",
        "          prediction=1e-10\n",
        "        return -np.log(prediction)\n",
        "\n",
        "def calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers):\n",
        "      correct = 0\n",
        "      total = int(60000 * validation_split)\n",
        "      validation_loss = 0.0\n",
        "      for i in range(59999, 59999 - total - 1, -1):\n",
        "          a_h_list = forward_propagation(theta, x_train[i].flatten().reshape((784, 1)), activation_func,no_of_hidden_layers)\n",
        "          prediction = np.argmax(a_h_list[-1])\n",
        "          if prediction == y_train[i]:\n",
        "              correct += 1\n",
        "          validation_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "      validation_accuracy = correct / total\n",
        "      validation_loss /= total\n",
        "      return validation_accuracy,validation_loss\n",
        "\n",
        "# Back propagation\n",
        "def back_propagation(a_h_list, y, inp, del_theta, theta, batch_size, activation_func,no_of_hidden_layers):\n",
        "    h_counter = len(a_h_list) - 1\n",
        "    grad_a = calc_aL(a_h_list[h_counter],y)\n",
        "    h_counter -= 2\n",
        "    for i in range(no_of_hidden_layers, -1, -1):\n",
        "        if i == 0:\n",
        "            del_w = np.dot(grad_a, inp.T)\n",
        "            del_b = grad_a\n",
        "            del_theta[i] = np.add(del_theta[i], del_w)\n",
        "            del_theta[i + no_of_hidden_layers + 1] = np.add(del_theta[i + no_of_hidden_layers + 1], del_b)\n",
        "            break\n",
        "        del_w = np.dot(grad_a, a_h_list[h_counter].T)\n",
        "        del_b = grad_a\n",
        "        del_theta[i] = np.add(del_theta[i], del_w)\n",
        "        del_theta[i + no_of_hidden_layers + 1] = np.add(del_theta[i + no_of_hidden_layers + 1], del_b)\n",
        "        grad_h_prev = np.dot(theta[i].T, grad_a)\n",
        "        grad_a = grad_h_prev * calc_gdash(a_h_list[h_counter - 1], activation_func)\n",
        "        h_counter -= 2\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(eta, batch_size, epoch, theta, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    for itr in range(epoch):\n",
        "        # Initialize gradients and total loss\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights after every mini-batch\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    #temp=np.subtract(theta[j],eta*del_theta[j])\n",
        "                    #norm=np.linalg.norm(temp)\n",
        "                    #theta[j]=temp/norm\n",
        "                    theta[j] = np.subtract(theta[j], eta * del_theta[j])\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "      })\n",
        "\n",
        "        # print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "# Momentum Gradient Descent\n",
        "def momentum_gradient_descent(eta, batch_size, epoch, theta, beta, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    # Initialize previous history\n",
        "    prev_history = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for itr in range(epoch):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights using momentum\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(del_theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    prev_history[j] = np.add(beta * prev_history[j],eta * (del_theta[j]))\n",
        "                    theta[j] = np.subtract(theta[j], eta * prev_history[j])\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "        })\n",
        "       #print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "# Nestrov Gradient Descent\n",
        "def nesterov_gradient_descent(eta, batch_size, epoch, theta, beta, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    # Initialize previous history\n",
        "    prev_history = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for itr in range(epoch):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Update weights using Nesterov accelerated gradient descent\n",
        "            updated_theta = [theta[j] - beta * prev_history[j] for j in range(len(theta))]\n",
        "\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(updated_theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, updated_theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights using momentum\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(del_theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    prev_history[j] = np.add(beta * prev_history[j],eta*(del_theta[j]))\n",
        "                    theta[j] = np.subtract(theta[j], prev_history[j])\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "        # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "        })\n",
        "        #print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "# RMS_Prop\n",
        "def rmsprop(eta, batch_size, epoch, theta, beta, eps, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    # Initialize first  moment estimates\n",
        "    v_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for itr in range(epoch):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights using Adam optimizer\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    v_theta[j] = beta * v_theta[j] + (1 - beta) * (del_theta[j] ** 2)\n",
        "\n",
        "                    # Update weights\n",
        "                    theta[j] = np.subtract(theta[j], eta * (del_theta[j]/ (np.sqrt(v_theta[j] + eps))))\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "         # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "        })\n",
        "        #print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "\n",
        "# Adam Optimizer\n",
        "def adam_optimizer(eta, batch_size, epoch, theta, beta1, beta2, eps, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    # Initialize first and second moment estimates\n",
        "    m_theta = [np.zeros_like(param) for param in theta]\n",
        "    v_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for itr in range(epoch):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights using Adam optimizer\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    m_theta[j] = beta1 * m_theta[j] + (1 - beta1) * del_theta[j]\n",
        "                    v_theta[j] = beta2 * v_theta[j] + (1 - beta2) * (del_theta[j] ** 2)\n",
        "\n",
        "                    # Bias correction\n",
        "                    m_hat = m_theta[j] / (1 - np.power(beta1, itr + 1))\n",
        "                    v_hat = v_theta[j] / (1 - np.power(beta2, itr + 1))\n",
        "\n",
        "                    # Update weights\n",
        "                    theta[j] = np.subtract(theta[j], eta * m_hat / (np.sqrt(v_hat) + eps))\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "         # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "        })\n",
        "        #print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "# nadam Optimizer\n",
        "def nadam_optimizer(eta, batch_size, epoch, theta, beta1, beta2, eps, activation_func, validation_split, loss_type, alpha,no_of_hidden_layers):\n",
        "    # Initialize first and second moment estimates\n",
        "    m_theta = [np.zeros_like(param) for param in theta]\n",
        "    v_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for itr in range(epoch):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        del_theta = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "        # Iterate through the training data\n",
        "        for i in tqdm(range(int(60000 * (1 - validation_split)))):\n",
        "            # Forward propagation\n",
        "            a_h_list = forward_propagation(theta, np.float128(x_train[i].flatten().reshape((784, 1))), activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss += calc_loss(a_h_list[-1], y_train[i], loss_type)\n",
        "\n",
        "            # Update accuracy\n",
        "            if np.argmax(a_h_list[-1]) == y_train[i]:\n",
        "                total_acc += 1\n",
        "\n",
        "            # Backpropagation\n",
        "            back_propagation(a_h_list, y_train[i], np.float128((x_train[i].flatten()).reshape((784, 1))), del_theta, theta, batch_size, activation_func,no_of_hidden_layers)\n",
        "\n",
        "            # Update weights using Adam optimizer\n",
        "            if i % batch_size == 0 and i != 0:\n",
        "                for j in range(len(theta)):\n",
        "                    del_theta[j] = (del_theta[j] / batch_size)+alpha*theta[j]\n",
        "                    m_theta[j] = beta1 * m_theta[j] + (1 - beta1) * del_theta[j]\n",
        "                    v_theta[j] = beta2 * v_theta[j] + (1 - beta2) * (del_theta[j] ** 2)\n",
        "\n",
        "                    # Bias correction\n",
        "                    m_hat = m_theta[j] / (1 - np.power(beta1, itr + 1))\n",
        "                    v_hat = v_theta[j] / (1 - np.power(beta2, itr + 1))\n",
        "\n",
        "                    # Update weights\n",
        "                    theta[j] = np.subtract(theta[j], (eta / (np.sqrt(v_hat) + eps))*((beta1*m_hat)+((1-beta1)*(del_theta[j]/(1 - np.power(beta1, itr + 1))))))\n",
        "                    del_theta[j] = del_theta[j] * 0\n",
        "\n",
        "         # Calculate validation loss and accuracy\n",
        "        validation_accuracy,validation_loss=calc_val_loss_acc(theta,validation_split,activation_func,loss_type,no_of_hidden_layers)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        wandb.log({\n",
        "          'Loss': total_loss / (60000 * (1 - validation_split)),\n",
        "          'Accuracy': total_acc / (60000 * (1 - validation_split)),\n",
        "          'Validation_Loss': validation_loss,\n",
        "          'Validation_Accuracy': validation_accuracy\n",
        "        })\n",
        "        #print(f\"Epoch {itr + 1}/{epoch}, Loss: {total_loss / (60000 * (1 - validation_split))}, Accuracy: {total_acc / (60000 * (1 - validation_split))}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy}\")\n",
        "\n",
        "def run_optimizer(eta, batch_size, epoch, theta, beta, beta1, beta2, eps, activation_func, validation_split, loss_type, alpha,optimizer,no_of_hidden_layers):\n",
        "    if(optimizer==\"sgd\"):\n",
        "      gradient_descent(eta,1,epoch,theta,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "    elif(optimizer==\"momentum\"):\n",
        "      momentum_gradient_descent(eta,batch_size,epoch,theta,beta,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "    elif(optimizer==\"nestrov\"):\n",
        "      nesterov_gradient_descent(eta,batch_size,epoch,theta,beta,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "    elif(optimizer==\"rmsprop\"):\n",
        "      rmsprop(eta,batch_size,epoch,theta,beta,eps,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "    elif(optimizer==\"adam\"):\n",
        "      adam_optimizer(eta,batch_size,epoch,theta,beta1,beta2,eps,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "    elif(optimizer==\"nadam\"):\n",
        "      nadam_optimizer(eta,batch_size,epoch,theta,beta1,beta2,eps,activation_func,validation_split,loss_type,alpha,no_of_hidden_layers)\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'Validation_Accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'eta': {'values': [1e-2, 1e-3, 1e-1, 1e-4]},\n",
        "        'batch_size': {'values': [16, 32, 64]},\n",
        "        'no_of_hidden_layers':{'values':[3,4,5]},\n",
        "        'each_layer_neuron':{'values':[32,64,128]},\n",
        "        'eps':{'values':[1e-10]},\n",
        "        'validation_split':{'values':[0.1]},\n",
        "        'epoch': {'values': [5]},\n",
        "        'beta': {'values': [0.9]},\n",
        "        'beta1': {'values': [0.9]},\n",
        "        'beta2': {'values': [0.999]},\n",
        "        'alpha': {'values': [0.0005, 0.001,0]},\n",
        "        'optimizer': {'values': ['adam', 'nadam', 'rmsprop', 'sgd', 'momentum', 'nestrov']},\n",
        "        'loss_type':{'values':['cross_entropy','mse']},\n",
        "        'activation_func':{'values':['sigmoid','ReLU','tanh']},\n",
        "        'initialization_func':{'values':['random','Xavier']}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Main code\n",
        "'''def main():\n",
        "    no_of_hidden_layers = 3\n",
        "    each_layer_neuron=64\n",
        "    theta = initialize_weights(\"random\", 784, no_of_hidden_layers, 10, each_layer_neuron)\n",
        "    eta = 1e-2\n",
        "    batch_size = 32\n",
        "    epoch = 5\n",
        "    beta=0.9\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    eps = 1e-10\n",
        "    alpha=0.0005\n",
        "    validation_split = 0.1\n",
        "    activation_func = \"sigmoid\"\n",
        "    loss_type = \"cross_entropy\"\n",
        "    optimizer=\"adam\"\n",
        "    run_optimizer(eta, batch_size, epoch, theta, beta, beta1, beta2, eps, activation_func, validation_split, loss_type, alpha,optimizer,no_of_hidden_layers)'''\n",
        "\n",
        "def train():\n",
        "    # Initialize wandb\n",
        "    wandb.init()\n",
        "\n",
        "    # Set your hyperparameters from wandb config\n",
        "    config = wandb.config\n",
        "    theta = initialize_weights(config.initialization_func, 784, config.no_of_hidden_layers, 10, config.each_layer_neuron)\n",
        "    # Train your model\n",
        "    run_optimizer(config.eta, config.batch_size, config.epoch, theta, config.beta, config.beta1, config.beta2, config.eps, config.activation_func, config.validation_split, config.loss_type, config.alpha, config.optimizer, config.no_of_hidden_layers)\n",
        "\n",
        "\n",
        "# Initialize wandb sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"deep_learn_assignment_1\")\n",
        "\n",
        "# Run wandb agent to execute the sweep\n",
        "wandb.agent(sweep_id, function=train,count =2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5xCSqU_m1nH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG2yghvIGYdRxnWm6prD3i"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26086e13a33f4883bf6f1c6e9b64701a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6a3c6f603cd4af4b8fb629d6527325a",
              "IPY_MODEL_a8515cffb7324589a8ad049827f4fccc"
            ],
            "layout": "IPY_MODEL_f2a3ce8eed504589b7cb064dc3f9e360"
          }
        },
        "e6a3c6f603cd4af4b8fb629d6527325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12c315ce7434ff8a456f2adbb789a47",
            "placeholder": "​",
            "style": "IPY_MODEL_986da0d7a35f4a66bd3dd44e4adaacbe",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "a8515cffb7324589a8ad049827f4fccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21233b0c5fa04e0d83e63d0b69b6d9fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b7191559d3e4ba5a40a542c4115fb9f",
            "value": 1
          }
        },
        "f2a3ce8eed504589b7cb064dc3f9e360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12c315ce7434ff8a456f2adbb789a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986da0d7a35f4a66bd3dd44e4adaacbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21233b0c5fa04e0d83e63d0b69b6d9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7191559d3e4ba5a40a542c4115fb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6197395d2f849f2b851536402482a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7d2e6a5140f42bc8f8d37832a8cae73",
              "IPY_MODEL_6106fe2e5cb54358a7cb4ac0682d7cf8"
            ],
            "layout": "IPY_MODEL_b99aebdc96ba44ff9d973fcb909834be"
          }
        },
        "c7d2e6a5140f42bc8f8d37832a8cae73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79c76a5289f5480b88dbe06cb7dfc8f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ba74faef64f64b8d8a0e7beadae99586",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "6106fe2e5cb54358a7cb4ac0682d7cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21e3f7e538b43448f8fa3ade1b61a32",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e02a0968f79f4ed2a1b2bcaee2088be3",
            "value": 1
          }
        },
        "b99aebdc96ba44ff9d973fcb909834be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c76a5289f5480b88dbe06cb7dfc8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba74faef64f64b8d8a0e7beadae99586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d21e3f7e538b43448f8fa3ade1b61a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02a0968f79f4ed2a1b2bcaee2088be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}